---
title: "Analysing the Russia Report"
author: "Andi Fugard (almost@gmail.com, @[inductivestep](https://twitter.com/InductiveStep))"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    self_contained: no
    toc: yes
    toc_float: yes
    collapsed: false
---

(See the github repo [here](https://github.com/InductiveStep/Russia-Report).)


The report is available on the [ISC website](http://isc.independent.gov.uk/news-archive/21july2020) and [in this github repository](20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf).

First, load it into R.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(pdftools)
library(stringr)
rr_text <- pdf_text("20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf")
```
The `pdf_text` command returns a character vector with one element per PDF page. The main report text is on pages 8-42.


## Finding the juiciest pages

I'd like to know where the juicy pages are - one way to index them is by number of reduction marks, "***".

First try for one page to get the hang of it. I had a look at page 10 and there was one.

```{r}
str_count(rr_text[10], pattern = "\\*\\*\\*")
```

It worked - hurrah. Try for page 8 which has none.

```{r}
str_count(rr_text[8], pattern = "\\*\\*\\*")
```

And page 12, which has 8:

```{r}
str_count(rr_text[12], pattern = "\\*\\*\\*")
```

All good. `str_count` takes a vector, so we can do the whole report in one go:

```{r}
redact_n <- str_count(rr_text, pattern = "\\*\\*\\*")
```

Let's stick these in a tibble, alongside the (pdf, as opposed to printed) page number and original page text.

```{r}
rr_tib <- tibble(page = 1:length(rr_text),
                 text = rr_text,
                 redactions = redact_n)
```

### Histogram

Now a histogram of those redactions:

```{r message=FALSE}
ggplot(rr_tib, aes(x=redactions)) +
  geom_histogram(binwidth = 1, fill = "firebrick", color = "white") +
  labs(x = "Number of redactions",
       y = "Count",
       title = "Histogram of redactions on each page of the Russia Report") +
  theme_classic()
```

### Which pages have the most redactions?

```{r}
rr_tib %>%
  filter(redactions > 10) %>%
  select(page, redactions) %>%
  arrange(redactions)
```

The section on PDF pages 37 and 38 (printed page nums 30 and 31) is the winner: "Rising to the challenge".

### The most redacted pages (pp. 30-32 in the printed report)

Here's a link to the [pdf pages](https://inductivestep.github.io/Russia-Report/20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf#page=37).

```{r results='asis'}
gsub(pattern = "\\*\\*\\*",
     replace = "\\*\\*\\*[redacted]\\*\\*\\*",
     x = rr_tib$text[37:39]) %>%
  writeLines()
```



## Word counts

Let's try the `tidytext` package, which is introduced in a [great book](https://www.tidytextmining.com/) by [Julia Silge](https://juliasilge.com/) and [David Robinson](http://varianceexplained.org/).

```{r}
library(tidytext)
```

Here's a tidy tibble with all the words:

```{r}
rr_words <- rr_tib %>%
  unnest_tokens(word, # the name of the new column
                text) # the column with text
rr_words
```

And the top 20 most common words:

```{r}
rr_words %>%
  anti_join(stop_words, by = "word") %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(20) %>%
  kable()
```


## Sentence-level analysis

Is there a relationship between which intelligence service (MI5, MI6, or GCHQ) is mentioned and whether there is a redaction in that sentence?

Again use `tidytext`, but this time at the sentence level.

```{r}
rr_sentences <- rr_tib %>%
  unnest_sentences(sentence, text, to_lower = FALSE)

rr_sentences %>%
  slice_sample(n = 10) %>%
  kable()
```

That worked reasonably well, though citations at the end of sentences confused it (possible to fix with a regex), footnotes need to be addressed separately (sentences beginning numbers, once the aforementioned sentence problem has been fixed), and it probably doesn't deal with sentences which cross pages - definitely not when there's a footnote on the first page (possible to fix by removing footnotes then gluing all the sentences together and unnesting again).

Next: code sentences in terms of whether they mention an intel agency.

```{r}
rr_sentences <- rr_sentences %>%
  mutate(
    redacted       = 0+str_detect(sentence, "\\*\\*\\*"),
    mentioned_MI5  = 0+str_detect(sentence, "MI5"),
    mentioned_MI6  = 0+str_detect(sentence, "(MI6|SIS)"),
    mentioned_GCHQ = 0+str_detect(sentence, "GCHQ"),
    mentioned_intel_agency = pmax(mentioned_MI5,
                                  mentioned_MI6,
                                  mentioned_GCHQ),
    mentioned_code = paste0(mentioned_MI5,
                            mentioned_MI6,
                            mentioned_GCHQ)
  )
```

The `mentioned_code` is a three-bit string: 000 means no agency was mentioned, 100 is MI5 (and no others), 101 is MI6 (and no others), 001 is GCHQ (and no others). All combinations are also captured, e.g., 011 would be MI6 and GCHQ.

Let's count them:

```{r}
rr_sentences %>%
  count(mentioned_code) %>%
  arrange(desc(n)) %>%
  kable()
```

Does mentioning an intel agency (any of them) in a sentence make it more likely that the sentence will be reacted?

```{r}
mod_redact <- glm(redacted ~ mentioned_intel_agency,
                  data = rr_sentences, family = binomial)

summary(mod_redact)
```

Yes. The odds of a redaction are `r round(exp(coef(mod_redact))[2],1)` times greater if an intel service is mentioned.

```{r}
exp(coef(mod_redact))
```

How about the various patterns of mention, compared with no mention?

```{r}
mod_redact1 <- glm(redacted ~ mentioned_code,
                  data = rr_sentences, 
                  family = binomial)
summary(mod_redact1)
```

There only appears to be a difference if one (and only one) service is mentioned.

What sorts of texts get redacted which don't mention a service?


```{r}
rr_sentences %>%
  filter(mentioned_intel_agency == 0 & redacted == 1) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
     ) %>%
  select(page, nice_sentence) %>%
  kable()
```


