---
title: "Analysing the Russia Report"
author: "Andi Fugard (almost@gmail.com, @[inductivestep](https://twitter.com/InductiveStep))"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    self_contained: no
    toc: yes
    toc_float: yes
    collapsed: false
---

***WORK IN PROGRESS***

(See the github repo [here](https://github.com/InductiveStep/Russia-Report).)


The report is available on the [ISC website](http://isc.independent.gov.uk/news-archive/21july2020) and [in this github repository](20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf).

First, load it into R.

```{r message=FALSE, warning=FALSE}
devtools::install_github("inductivestep/handbag")
library(handbag)
library(tidyverse)
library(knitr)
library(pdftools)
library(stringr)
rr_text <- pdf_text("20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf")
```
The `pdf_text` command returns a character vector with one element per PDF page. The main report text is on pages 8-42.


# First go


## Finding the juiciest pages

I'd like to know where the juicy pages are - one way to count how many redactions there are, ***.

```{r}
redact_n <- str_count(rr_text, pattern = "\\*\\*\\*")
```

Let's stick these in a tibble, alongside the (pdf, as opposed to printed) page number and original page text.

```{r}
rr_tib <- tibble(page = 1:length(rr_text),
                 text = rr_text,
                 redactions = redact_n)
```

### Histogram

Now a histogram of those redactions:

```{r fig.height=3, fig.width=6, message=FALSE}
ggplot(rr_tib, aes(x=redactions)) +
  geom_histogram(binwidth = 1, fill = "firebrick", color = "white") +
  labs(x = "Number of redactions",
       y = "Count",
       title = "Histogram of redactions on each page of the Russia Report") +
  theme_classic()
```

### Which pages have the most redactions?

```{r}
rr_tib %>%
  filter(redactions > 10) %>%
  select(page, redactions) %>%
  arrange(redactions)
```

The section on PDF pages 37 and 38 (printed page nums 30 and 31) is the winner: "Rising to the challenge". Here's a link to the [pdf pages](https://inductivestep.github.io/Russia-Report/20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf#page=37).


## Word counts

Let's try the `tidytext` package, which is introduced in a [great book](https://www.tidytextmining.com/) by [Julia Silge](https://juliasilge.com/) and [David Robinson](http://varianceexplained.org/).

```{r}
library(tidytext)
```

Here's a tidy tibble with all the words:

```{r}
rr_words <- rr_tib %>%
  select(page,text) %>%
  unnest_tokens(word, # name of the new column
                text) # column with text

```

And the top 20 most common words:

```{r fig.height=6, fig.width=6}
rr_words %>%
  anti_join(stop_words, by = "word") %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(20) %>%
  ggplot(aes(x = reorder(word, n),
             y = n,
             fill = n)) +
    geom_bar(stat = "identity") + 
    coord_flip() +
    labs(y = "Count",
         x = "Word") + 
    theme(legend.position = "none")
```


## Sentence-level analysis

Is there a relationship between which intelligence service (MI5, MI6, or GCHQ) is mentioned and whether there is a redaction in that sentence?

Again use `tidytext`, but this time at the sentence level.

```{r}
rr_sentences <- rr_tib %>%
  unnest_sentences(sentence, text,
                   to_lower = FALSE) %>%
  select(-redactions) # remove page-level count of redactions

rr_sentences$sentence_i <- 1:nrow(rr_sentences)
```

That worked reasonably well, though:

* citations at the end of sentences confused it (possible to fix this using `unnest_regex`),
* footnotes need to be addressed separately (they are sentences beginning with numbers, once the aforementioned sentence problem has been fixed), and
* it doesn't deal with sentences which cross pages - definitely not when there's a footnote splitting them too (it may be possible to fix this problem by removing footnotes, gluing all the sentences together, and unnesting again).

Next: code redactions and whether sentences mention one of the big three intel agencies.

I'll use `fuzzyjoin` for this, which joins two tables based on a regular expression.

```{r}
library(fuzzyjoin)

mapping <- tribble(
  ~regex, ~code,
  "MI5|[s|S]ecurity [s|S]ervice",         "intel_MI5",
  "MI6|SIS|Secret Intelligence Service",   "intel_MI6",
  "GCHQ",                                  "intel_GCHQ",
  "Defence Intelligence",                  "intel_DI",
  "GRU",                                   "intel_GRU",
  "\\*\\*\\*",                             "redacted"
)
```
Now, reshape so that there's a binary predictor matrix.

```{r}
rr_mentions <- rr_sentences %>%
  regex_left_join(mapping,
                  by = c(sentence = "regex")) %>%
  group_by(sentence_i, code) %>%
  count() %>%
  pivot_wider(names_from = code,
              values_from = n,
              values_fill = 0) %>%
  rowwise() %>%
  mutate(any_intel_agency = 
           max(c_across(starts_with("intel_")))) %>%
  select(-"NA")

rr_sentences <- rr_sentences %>%
  left_join(rr_mentions, by = "sentence_i")
```

Now make a summary variable of the services mentioned.

```{r}
rr_sentences$mentioned_services <- rr_sentences %>%
  select(starts_with("intel_")) %>%
  handbag::binary_patterns_var(strip_prefix = "intel_")
```

Let's count them:

```{r}
rr_sentences %>%
  count(mentioned_services) %>%
  arrange(desc(n)) %>%
  kable(col.names = c("Service(s) mentioned", "n"))
```

Does mentioning an intel agency (any of them) in a sentence make it more likely that the sentence will have a redaction?

```{r message=FALSE}
any_redact_tab <- rr_sentences %>%
  group_by(any_intel_agency) %>%
  summarise(perc_redacted = 100*mean(redacted)) %>%
  mutate(any_intel_agency = c("None mentioned",
                              "One or more"))

any_redact_tab %>%
  ggplot(aes(x = any_intel_agency,
             y = perc_redacted,
             fill = any_intel_agency)) +
    geom_col() +
    labs(x = "Any intel agency mentioned",
         y = "% sentences redacted") +
    expand_limits(y = 100) +
    theme(legend.position = "none")
```

Yes. Sentences mentioning any service are `r round(with(any_redact_tab, perc_redacted[2] / perc_redacted[1]),1)` times more likely to contain a redaction.

How about the various patterns of mention versus no mention?

```{r message=FALSE}
redacted_tab <- rr_sentences %>%
  group_by(mentioned_services, redacted) %>%
  summarise(n = n()) %>%
  mutate(perc = 100*n/sum(n)) %>%
  pivot_wider(names_from   = redacted,
              values_from  = c(n,perc),
              values_fill  = 0,
              names_prefix = "redact_")

redacted_tab %>%
  select(-perc_redact_0) %>%
  arrange(desc(perc_redact_1)) %>%
  kable(col.names = c("", "Unredacted (n)",
                      "Redacted (n)",
                      "Redacted (%)"),
        digits = 0)
```


```{r message=FALSE}
redacted_tab %>%
  mutate(percentage_redacted = perc_redact_1) %>%
  ggplot(aes(x = reorder(mentioned_services, percentage_redacted),
             y = percentage_redacted,
             fill = mentioned_services)) +
    geom_col() + 
    coord_flip() +
    labs(x = "Services mentioned in sentence",
         y = "% of sentences with a redaction",
         title = "Predictors of redacted sentences") + 
    expand_limits(y = 105) +
    theme(legend.position = "none") +
    geom_text(aes(label = round(percentage_redacted,0),
                  y = percentage_redacted+1,
                  hjust = 0))
```

(The winner there, GCHQ and GRU, is only one sentence!)


### Some text

#### Sentences mentioning a service with a redaction

**Note** be careful with the numbers - they're mostly superscript citations!


```{r}
rr_sentences %>%
  filter(any_intel_agency == 1 & redacted == 1) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, mentioned_services, nice_sentence) %>%
  kable()
```

#### Sentences mentioning a service with no redaction

**Note** be careful with the numbers - they're mostly superscript citations!


```{r}
rr_sentences %>%
  filter(any_intel_agency == 1 & redacted == 0) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, mentioned_services, nice_sentence) %>%
  kable()
```




#### Sentences mentioning none of the services but still redacted

**Note** be careful with the numbers - they're mostly superscript citations!

```{r}
rr_sentences %>%
  filter(any_intel_agency == 0 & redacted == 1) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, nice_sentence) %>%
  kable()
```

## Sentiment analysis

Here's the plan:

1. Take the sentence level analysis from above.
2. Unnest further to the word level.
3. Explore some of relationships with sentiment.

I'll use the word-emotion lexicon by [Saif M. Mohammad and Peter D. Turney (2013)](https://doi.org/10.1111/j.1467-8640.2012.00460.x):

```{r}
library(textdata)
nrc_sentiments <- get_sentiments("nrc")
```

```{r}
rr_sentiment <- rr_sentences %>%
  unnest_tokens(word,
                sentence, drop = F)

rr_sentiment$word_i <- 1:nrow(rr_sentiment)

rr_sentiment <- rr_sentiment %>%
  inner_join(nrc_sentiments, by = "word")
```

Let's see which words appear by sentiment:

```{r}
library(ggwordcloud)
```

```{r message=FALSE, warning=FALSE}
makeWordCloud <- function(theSentiment) {
  rr_sentiment %>%
    filter(sentiment == theSentiment) %>%
    group_by(word) %>%
    summarise(n = n()) %>%
    mutate(prop = n/sum(n)) %>%
    filter(n >= 5) %>%
    ggplot(aes(label = word, size = log1p(prop), col = log1p(n))) +
    scale_size_area(max_size = 12) +
    geom_text_wordcloud() +
    theme_minimal() + 
    labs(title = theSentiment)
}

allTheClouds <- map(unique(rr_sentiment$sentiment)
                      %>% na.omit(), makeWordCloud)
allTheClouds
```



I'm not entirely convinced by the words picked out for each of those sentiments - maybe anger, disgust, and sadness show something interesting.

```{r}
toView = c("anger", "disgust", "sadness")
```

First glue the word-level analysis back to the sentences.

I just want to know if a sentiment has been expressed at least once per sentence (the `b` below is for Boolean).

```{r}
sentiment_counts <- rr_sentiment %>%
  group_by(sentence_i, sentiment) %>%
  summarise(n = n()) %>%
  mutate(b = as.numeric(n > 0))

sentiment_counts <- rr_sentences %>%
  inner_join(sentiment_counts, by = "sentence_i")
```

Plot by page as a proportion of words which have a sentiment coded.

```{r fig.height=3, fig.width=6}
emo_by_page <- sentiment_counts %>%
  group_by(page, sentiment) %>%
  filter(sentiment != "NA") %>%
  summarise(n = n()) %>%
  mutate(p = n/sum(n))

emo_by_page %>%
  filter(sentiment %in% toView) %>%
  ggplot(aes(x = page, y = n, color = sentiment)) +
    geom_line() +
    labs(x = "Page", y = "Count")
```

Looks like a spike for "anger" there on PDF [page 18](https://inductivestep.github.io/Russia-Report/20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf#page=18).

```{r}
emo_by_page %>%
  filter (n > 10 & sentiment %in% toView) %>%
  kable(col.names = c("Page", "Sentiment", "N", "Proportion"))
```

```{r}
sentiment_counts %>%
  filter(page == 18 & sentiment %in% toView) %>%
  select(sentiment, sentence) %>%
  kable()
```




## Word cloud of redactions

Now we have data labelled in various ways, it's easy to make a word cloud comparing words in sentences which do with those which don't contain redactions.

```{r fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
rr_sentiment %>%
  anti_join(stop_words) %>%
  mutate(redacted = recode(redacted,
                           `0` = "No redactions",
                           `1` = "One or more redactions")) %>%
  group_by(redacted, word) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  filter(prop > .002) %>%
  ggplot(aes(label = word, size = log1p(prop), color = redacted)) +
    scale_size_area(max_size = 11) +
    geom_text_wordcloud() +
    theme_minimal() + 
    facet_grid(cols = vars(redacted))
```



```{r fig.height=24, fig.width=6, message=FALSE, warning=FALSE}
excluded_words <- c("gchq", "mi6", "mi5", "sis",
                    "intelligence", "www.mi5")

rr_sentiment %>%
  anti_join(stop_words) %>%
  mutate(redacted = recode(redacted,
                           `0` = "No redactions",
                           `1` = "One or more redactions")) %>%
  group_by(redacted, mentioned_services, word) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  filter(prop > .005 & !(word %in% excluded_words)) %>%
  ggplot(aes(label = word, size = log1p(prop), color = redacted)) +
    scale_size_area(max_size = 9) +
    geom_text_wordcloud() +
    theme_minimal() + 
    facet_grid(cols = vars(redacted),
               rows = vars(mentioned_services))
```

