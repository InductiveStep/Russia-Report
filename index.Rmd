---
title: "Analysing the Russia Report"
author: "Andi Fugard (almost@gmail.com, @[inductivestep](https://twitter.com/InductiveStep))"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    self_contained: no
    toc: yes
    toc_float: yes
    collapsed: false
---

***WORK IN PROGRESS***

(See the github repo [here](https://github.com/InductiveStep/Russia-Report).)


The report is available on the [ISC website](http://isc.independent.gov.uk/news-archive/21july2020) and [in this github repository](20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf).

First, load it into R.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(pdftools)
library(stringr)
rr_text <- pdf_text("20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf")
```
The `pdf_text` command returns a character vector with one element per PDF page. The main report text is on pages 8-42.


## Finding the juiciest pages

I'd like to know where the juicy pages are - one way to count how many redactions there are, ***.

```{r}
redact_n <- str_count(rr_text, pattern = "\\*\\*\\*")
```

Let's stick these in a tibble, alongside the (pdf, as opposed to printed) page number and original page text.

```{r}
rr_tib <- tibble(page = 1:length(rr_text),
                 text = rr_text,
                 redactions = redact_n)
```

### Histogram

Now a histogram of those redactions:

```{r fig.height=3, fig.width=6, message=FALSE}
ggplot(rr_tib, aes(x=redactions)) +
  geom_histogram(binwidth = 1, fill = "firebrick", color = "white") +
  labs(x = "Number of redactions",
       y = "Count",
       title = "Histogram of redactions on each page of the Russia Report") +
  theme_classic()
```

### Which pages have the most redactions?

```{r}
rr_tib %>%
  filter(redactions > 10) %>%
  select(page, redactions) %>%
  arrange(redactions)
```

The section on PDF pages 37 and 38 (printed page nums 30 and 31) is the winner: "Rising to the challenge".

### The most redacted pages (pp. 30-32 in the printed report)

Here's a link to the [pdf pages](https://inductivestep.github.io/Russia-Report/20200721_HC632_CCS001_CCS1019402408-001_ISC_Russia_Report_Web_Accessible.pdf#page=37).

```{r results='asis'}
gsub(pattern = "\\*\\*\\*",
     replace = "\\*\\*\\*[redacted]\\*\\*\\*",
     x = rr_tib$text[37:39]) %>%
  writeLines()
```



## Word counts

Let's try the `tidytext` package, which is introduced in a [great book](https://www.tidytextmining.com/) by [Julia Silge](https://juliasilge.com/) and [David Robinson](http://varianceexplained.org/).

```{r}
library(tidytext)
```

Here's a tidy tibble with all the words:

```{r}
rr_words <- rr_tib %>%
  select(page,text) %>%
  unnest_tokens(word, # name of the new column
                text) # column with text

rr_words %>%
  head(10) %>%
  kable()
```

And the top 20 most common words:

```{r}
rr_words %>%
  anti_join(stop_words, by = "word") %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(20) %>%
  kable()
```


## Sentence-level analysis

Is there a relationship between which intelligence service (MI5, MI6, or GCHQ) is mentioned and whether there is a redaction in that sentence?

Again use `tidytext`, but this time at the sentence level.

```{r}
rr_sentences <- rr_tib %>%
  unnest_sentences(sentence, text,
                   to_lower = FALSE) %>%
  select(-redactions) # nuke the page-level count of redactions

rr_sentences %>%
  slice_sample(n = 5) %>%
  kable()
```

That worked reasonably well, though citations at the end of sentences confused it (possible to fix using `unnest_regex`), footnotes need to be addressed separately (they are sentences beginning with numbers, once the aforementioned sentence problem has been fixed), and it probably doesn't deal with sentences which cross pages - definitely not when there's a footnote splitting them too (possible to fix this problem by removing footnotes, gluing all the sentences together, and unnesting again).

Next: code whether sentences mention one of the big three intel agencies.

```{r}
rr_sentences <- rr_sentences %>%
  mutate(
    redacted       = 0+str_detect(sentence, "\\*\\*\\*"),
    mentioned_MI5  = 0+str_detect(sentence, "MI5"),
    mentioned_MI6  = 0+str_detect(sentence, "(MI6|SIS)"),
    mentioned_GCHQ = 0+str_detect(sentence, "GCHQ"),
    mentioned_intel_agency = pmax(mentioned_MI5,
                                  mentioned_MI6,
                                  mentioned_GCHQ),
    mentioned_code = paste0(mentioned_MI5,
                            mentioned_MI6,
                            mentioned_GCHQ)
  )
```

The `mentioned_code` is a three-bit string: 000 means no agency was mentioned, 100 is MI5 (and no others), 010 is MI6 (and no others), 001 is GCHQ (and no others). All combinations are also captured, e.g., 011 would be MI6 and GCHQ.

This next bit could be automated...

```{r}
service_mentions <- tibble(
  mentioned_code = c("000", "111", "001", "010",
                     "100", "011", "101", "110"),
  mentioned_services = c("None mentioned",
                        "All",
                        "GCHQ",
                        "MI6/SIS",
                        "MI5",
                        "MI6 & GCHQ",
                        "MI5 & GCHQ",
                        "MI5 & MI6")
)
rr_sentences <- left_join(rr_sentences, service_mentions) %>%
  select(-mentioned_code)
```


Let's count them:

```{r}
rr_sentences %>%
  count(mentioned_services) %>%
  arrange(desc(n)) %>%
  kable(col.names = c("Service(s) mentioned", "n"))
```

Does mentioning an intel agency (any of them) in a sentence make it more likely that the sentence will have a redaction?

```{r message=FALSE}
any_redact_tab <- rr_sentences %>%
  group_by(mentioned_intel_agency) %>%
  summarise(perc_redacted = 100*mean(redacted)) %>%
  mutate(mentioned_intel_agency = c("No intel service",
                                    "One or more"))

any_redact_tab %>%
  kable(col.names = c("Mentioned",
                      "% of sentences redacted"),
        digits = c(0,1))
```

Yes. Sentences mentioning any service are `r round(with(any_redact_tab, perc_redacted[2] / perc_redacted[1]),1)` times more likely to contain a redaction.

How about the various patterns of mention versus no mention?

```{r message=FALSE}
rr_sentences %>%
  group_by(mentioned_services) %>%
  summarise(percentage_redacted = 100*mean(redacted)) %>%
  arrange(desc(percentage_redacted)) %>%
  kable(col.names = c("Mentioned services",
                      "% of sentences redacted"),
        digits = c(0,1))
```

### Some text

#### Sentences mentioning a service with a redaction

**Note** be careful with the numbers - they're mostly superscript citations!


```{r}
rr_sentences %>%
  filter(mentioned_intel_agency == 1 & redacted == 1) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, mentioned_services, nice_sentence) %>%
  kable()
```

#### Sentences mentioning a service with no redaction

**Note** be careful with the numbers - they're mostly superscript citations!


```{r}
rr_sentences %>%
  filter(mentioned_intel_agency == 1 & redacted == 0) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, mentioned_services, nice_sentence) %>%
  kable()
```




#### Sentences mentioning none of the services but still redacted

**Note** be careful with the numbers - they're mostly superscript citations!

```{r}
rr_sentences %>%
  filter(mentioned_intel_agency == 0 & redacted == 1) %>%
  mutate(nice_sentence = gsub(pattern = "\\*\\*\\*",
         replace = "\\*\\*\\*[redacted]\\*\\*\\*",
         x = sentence)
  ) %>%
  select(page, nice_sentence) %>%
  kable()
```

## Sentiment analysis

Here's the plan:

1. Take the sentence level analysis from above.
2. Unnest further to the word level.
3. Explore some of relationships with sentiment.

I'll use the word-emotion lexicon by [Saif M. Mohammad and Peter D. Turney (2013)](https://doi.org/10.1111/j.1467-8640.2012.00460.x):

```{r}
library(textdata)
nrc_sentiments <- get_sentiments("nrc")
```

```{r}
rr_sentiment <- rr_sentences %>%
  mutate(sentence_i = 1:nrow(rr_sentences)) %>%
  unnest_tokens(word,
                sentence, drop = F)

rr_sentiment$word_i <- 1:nrow(rr_sentiment)

rr_sentiment <- rr_sentiment %>%
  left_join(nrc_sentiments, by = "word")
```

Let's see which words appear by sentiment:

```{r}
library(ggwordcloud)
```


```{r}
makeWordCloud <- function(theSentiment) {
  rr_sentiment %>%
    filter(sentiment == theSentiment) %>%
    group_by(word) %>%
    count() %>%
    filter(n >= 10) %>%
    ggplot(aes(label = word, size = n)) +
    scale_size_area(max_size = 15) +
    geom_text_wordcloud() +
    theme_minimal() + 
    labs(title = theSentiment)
}

allTheClouds <- map(unique(rr_sentiment$sentiment)
                      %>% na.omit(), makeWordCloud)
allTheClouds
```











### Back to sentences

```{r}
sentiment_counts <- rr_sentiment %>%
  group_by(sentence_i, sentiment) %>%
  summarise(n = n()) %>%
  mutate(b = as.numeric(n > 0)) %>%
  pivot_wider(names_from = sentiment,
              values_from = c(n, b),
              values_fill = 0)

sentiment_counts <- rr_sentences %>%
  mutate(sentence_i = 1:nrow(rr_sentences)) %>%
  left_join(sentiment_counts, by = "sentence_i")
sentiment_counts 
```



## Word cloud of redactions

Now word cloud comparing words in sentences which do versus don't contain redactions.

```{r message=FALSE, warning=FALSE}
rr_sentiment %>%
  anti_join(stop_words) %>%
  mutate(redacted = recode(redacted,
                           `0` = "No",
                           `1` = "Yes")) %>%
  group_by(redacted, word) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n)) %>%
  filter(prop > .002) %>%
  ggplot(aes(label = word, size = prop, color = redacted)) +
    scale_size_area(max_size = 12) +
    geom_text_wordcloud() +
    theme_minimal() + 
    facet_grid(rows = vars(redacted))
```

